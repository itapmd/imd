---
title: Usage
---

{% include imdhead.html %}

<h1>Usage</h1>

<p>
After having <a href="compiling.html">compiled</a> IMD with the
suitable options, the simulation is started as follows:
<pre>
    imd_program [-r N] -p parameter_file
</pre>
The name of the IMD program is the same as the compilation target.
If the parameter -r N is present, where N is an integer number, the 
simulation is restarted from the checkpoint number N. The 
<a href="paramfile.html">parameter file</a> contains all further
<a href="params.html">parameters</a> describing the simulation.</p>

<h2> Parallel execution</h2>

<p>
IMD supports two parallelisation methods, OpenMP and MPI, which can
also be combined. If OpenMP is used, the number of threads in
each process has to specified by setting the envirent variable
OMP_NUM_TREADS. If MPI is used, the number of MPI processes 
must be stated at the program start. This is usually done with 
a (system dependent) startup script like the following ones:
<pre>
    mpirun -np P imd_program [-r N] -p parameter_file   # MPICH
    mpprun -n  P imd_program [-r N] -p parameter_file   # Cray T3E
</pre>
Here, P is the number of MPI processes. If P does not correspond to
the number of processes specified by the parameter <tt>cpu_dim</tt> in
the parameter file or if <tt>cpu_dim</tt> is missing, IMD chooses an
appropriate cpu grid by factorizing P evenly and by adhering to the
size distribution of <tt>cpu_dim</tt> (if given).</p>  

<p> 
If MPI and OpenMP are combined, one usually wants to run one MPI
process per computer node, with the number of OpenMP threads equal to
the number of CPUs per node. Care must be taken that exactly one
process is allocated on each node. In a pure MPI scheme, the number of
processes P should be equal to the total number of CPUs
available. Which parallelisation method is faster has to be checked
case by case.</p>

{% include imdfoot.html %}
